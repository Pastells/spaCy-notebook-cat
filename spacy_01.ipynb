{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trobant paraules, sintagmes, noms i conceptes\n",
    "\n",
    "Traduït adaptat de https://github.com/Cristianasp/spacy-notebook, podeu veure el curs original d'spaCy a https://course.spacy.io/chapter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducció a spaCy\n",
    "\n",
    "Al centre d'spaCy hi ha l'objecte encarregat del processament. Normalment l'anomenem `nlp`.\n",
    "\n",
    "Per exemple, per crear un objecte `nlp` per a l'anglès, podem carregar una classe de llengua i utilitzar-la com una funció per analitzar text.\n",
    "\n",
    "Aquest objecte conté tots els diferents components del pipeline.\n",
    "\n",
    "També inclou regles específiques de la llengua que s'utilitzen per convertir el text en paraules i signes de puntuació. spaCy admet molts idiomes diferents, disponibles a `spacy.lang`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# és típic carregar els models d'spacy amb el nom \"nlp\"\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "# aquest model inclou les següents peces\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la llengua\n",
    "from spacy.lang.ca import Catalan\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "# Create l'objecte nlp\n",
    "nlp = Catalan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan processem un text amb l'objecte `nlp`, spaCy crea un objecte `Doc`.\n",
    "\n",
    "El `Doc` és el contenidor central de spaCy: emmagatzema el text original i totes les anotacions predites.\n",
    "\n",
    "El `Doc` es comporta com una seqüència de Python: pots iterar sobre els seus tokens o accedir-hi per índex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processa un text amb nlp\n",
    "doc = nlp(\"Hola món\")\n",
    "\n",
    "# Itera sobre els tokens de Doc\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/token.png\" /> \n",
    "\n",
    "Els objectes `Token` representen els tokens individuals del document, com paraules o signes de puntuació.\n",
    "\n",
    "Per obtenir un token concret, podem indexar el document.\n",
    "\n",
    "Cada token disposa de diversos atributs, com ara `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hola món!\")\n",
    "\n",
    "# indexa Doc per tenir un sol token\n",
    "token = doc[1]\n",
    "\n",
    "print(token, type(token))\n",
    "print(token.text, type(token.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/span.png\" /> \n",
    "\n",
    "Un `Span` és un fragment del document format per un o més tokens. Serveix per sintagmes, n-grames o frases.\n",
    "\n",
    "És només una vista del `Doc`: no conté dades pròpies.\n",
    "\n",
    "Podem crear un `Span` utilitzant slicing de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Hola món, em dic Pol!\")\n",
    "\n",
    "# Un slice del Doc és un objecte Span\n",
    "span = doc[1:4]\n",
    "\n",
    "# Obté el text del span mitjançant l'atribut .text\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí pots veure alguns dels atributs de token disponibles:\n",
    "\n",
    "\"i\" és l'índex del token dins del document pare.\n",
    "\n",
    "\"text\" retorna el text del token.\n",
    "\n",
    "\"is_alpha\", \"is_punct\" i \"like_num\" retornen valors booleans que indiquen si el token consisteix en caràcters alfanumèrics, si és puntuació o si s'assembla a un número. Per exemple, un token \"10\" – u, zero – o la paraula \"deu\" – D, E, U.\n",
    "\n",
    "Aquests atributs també s'anomenen atributs lèxics: es refereixen a l'entrada del vocabulari i no depenen del context del token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"L'entrada costa 50€\")\n",
    "\n",
    "print(\"Index:   \", [token.i for token in doc])\n",
    "print(\"Text:    \", [token.text for token in doc])\n",
    "\n",
    "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:\", [token.is_punct for token in doc])\n",
    "print(\"like_num:\", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primers passos\n",
    "\n",
    "Comencem i provem spaCy!\n",
    "\n",
    "Part 1: Català\n",
    "\n",
    "Importa la classe de català de spacy.lang.ca i crea l'objecte nlp.\n",
    "\n",
    "Crea un doc i imprimeix el seu text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la classe de llengua catalana\n",
    "from spacy.lang.ca import Catalan\n",
    "\n",
    "# Crea l'objecte nlp\n",
    "nlp = Catalan()\n",
    "\n",
    "# Processa un text\n",
    "doc = nlp(\"Això és una frase.\")\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercici Documents, Spans i Tokens\n",
    "\n",
    "Quan crides nlp sobre una cadena de text, spaCy primer tokenitza el text i crea un objecte document. En aquest exercici, aprendràs més sobre el Doc, així com les seves vistes Token i Span.\n",
    "\n",
    "- Importa la classe de llengua anglesa i crea l'objecte nlp.\n",
    "- Processa el text i instancia un objecte Doc a la variable doc.\n",
    "- Selecciona el primer token del Doc i imprimeix el seu text.\n",
    "- Crea un slice del Doc per als tokens \"girasols grocs\" i \"els girasols grocs i les abelles\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"M'agraden el girasols grocs i les abelles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solució"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the English language class and create the nlp object\n",
    "from spacy.lang.ca import Catalan\n",
    "\n",
    "nlp = Catalan()\n",
    "doc = nlp(text)\n",
    "\n",
    "primer_token = doc[0]\n",
    "print(primer_token.text)\n",
    "\n",
    "girasols = doc[3:5]\n",
    "print(girasols.text)\n",
    "\n",
    "girasols_abelles = doc[3:8]\n",
    "print(girasols_abelles.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributs lèxics\n",
    "\n",
    "En aquest exemple, utilitzaràs els objectes Doc i Token de spaCy, i atributs lèxics per trobar percentatges en un text. Buscaràs dos tokens consecutius: un número i un signe de percentatge.\n",
    "\n",
    "Utilitza l'atribut de token `like_num` per comprovar si un token del doc s'assembla a un número.\n",
    "\n",
    "Obté el token següent al token actual del document. L'índex del token següent al doc és `token.i + 1`.\n",
    "\n",
    "Comprova si l'atribut text del token següent és un signe de percentatge \"%\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. \" \"Now less than 4% are.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solució"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    # comprova si és un número\n",
    "    if token.like_num:\n",
    "        # mira si el següent token és un '%'\n",
    "        next_token = doc[token.i + 1]\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage:\", token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Què passa en català (o castellà)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ca import Catalan\n",
    "\n",
    "nlp = Catalan()\n",
    "[t for t in nlp(\"6%\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tokenitzador no separa el %, així que aquest mètode no ens serveix. De fet, no trobarem un número amb `.like_num`.\n",
    "\n",
    "Sovint us trobareu amb problemes d'aquest estil. spaCy és un bon punt de partida, però a vegades cal modificar-lo. Per sort, està pensat per això. En general, haureu de buscar per internet la solució. En aquest cas podem afegir un sufix al tokenitzador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = nlp.Defaults.suffixes + [\"%\"]\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search\n",
    "[t for t in nlp(\"6%\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models estadístics\n",
    "\n",
    "Algunes de les coses més interessants que pots analitzar són específiques del context: per exemple, si una paraula és un verb o si un fragment de text és un nom de persona.\n",
    "\n",
    "### Què són els models estadístics?\n",
    "\n",
    "Els models estadístics permeten a spaCy fer prediccions en context. Això normalment inclou etiquetes de categoria gramatical, dependències sintàctiques i entitats amb nom.\n",
    "\n",
    "Els models s'entrenen amb grans conjunts de dades de textos d'exemple etiquetats.\n",
    "\n",
    "Es poden actualitzar amb més exemples per afinar les seves prediccions – per exemple, per funcionar millor amb les teves dades específiques.\n",
    "\n",
    "### Paquets de models\n",
    "\n",
    "https://spacy.io/usage/models\n",
    "\n",
    "spaCy proporciona diversos paquets de models pre-entrenats que pots descarregar utilitzant l'ordre \"spacy download\". Per exemple, el paquet \"en_core_web_sm\" és un model petit d'anglès que admet totes les capacitats bàsiques i està entrenat amb text web.\n",
    "\n",
    "El mètode spacy.load carrega un paquet de model pel nom i retorna un objecte nlp.\n",
    "\n",
    "El paquet proporciona els pesos binaris que permeten a spaCy fer prediccions.\n",
    "\n",
    "També inclou el vocabulari i meta-informació per indicar a spaCy quina classe de llengua utilitzar i com configurar el pipeline de processament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/models.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -m spacy download ca_core_news_sm\n",
    "# ! pip -m spacy download es_core_news_sm\n",
    "# ! pip -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicció d'etiquetes de categoria gramatical\n",
    "\n",
    "Per a cada token del Doc, podem imprimir el text i l'atribut \"pos_\", l'etiqueta de categoria gramatical predita [part of speech (PoS) en anglès].\n",
    "\n",
    "A spaCy, els atributs que retornen cadenes de text normalment acaben amb un guió baix; els atributs sense guió baix retornen valors enters.\n",
    "\n",
    "Aquí, el model predeix correctament \"menja\" com a verb i \"pizza\" com a nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega el model petit de català\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "# Processa un text\n",
    "doc = nlp(\"Ella es menja una pizza enorme\")\n",
    "\n",
    "# Itera sobre els tokens\n",
    "for token in doc:\n",
    "    # Imprimeix el text i l'etiqueta de categoria gramatical predita\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicció de dependències sintàctiques\n",
    "\n",
    "A més de les etiquetes de categoria gramatical, també podem predir com es relacionen les paraules. Per exemple, si una paraula és el subjecte de la frase o un objecte.\n",
    "\n",
    "L'atribut \"dep_\" retorna l'etiqueta de dependència predita.\n",
    "\n",
    "L'atribut head retorna el token principal sintàctic. També pots pensar-ho com el token pare al qual aquesta paraula està vinculada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esquema d'etiquetes de dependència"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dep_example.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per descriure dependències sintàctiques, spaCy utilitza un esquema d'etiquetes estandarditzat. Aquí hi ha un exemple d'algunes etiquetes comunes:\n",
    "\n",
    "El pronom \"She\" és un subjecte nominal vinculat al verb – en aquest cas, a \"ate\".\n",
    "\n",
    "El nom \"pizza\" és un objecte directe vinculat al verb \"ate\". És menjat pel subjecte, \"she\".\n",
    "\n",
    "El determinant \"the\", també conegut com a article, està vinculat al nom \"pizza\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicció d'entitats amb nom\n",
    "\n",
    "Named Entity Recognition (NER) en anglès.\n",
    "\n",
    "Les entitats amb nom són \"objectes del món real\" als quals s'assigna un nom – per exemple, una persona, una organització o un país.\n",
    "\n",
    "La propietat doc.ents et permet accedir a les entitats amb nom predites pel model.\n",
    "\n",
    "Retorna un iterador d'objectes Span, així que podem imprimir el text de l'entitat i l'etiqueta de l'entitat utilitzant l'atribut \"label_\".\n",
    "\n",
    "En aquest cas, el model està predint correctament \"Apple\" com a organització, \"U.K.\" com a entitat geopolítica i \"$1 billion\" com a diners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega el model petit de català\n",
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "\n",
    "def mostra_ner(text):\n",
    "    # Processa un text\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Itera sobre les entitats predites\n",
    "    for ent in doc.ents:\n",
    "        # Imprimeix el text de l'entitat i l'etiqueta\n",
    "        print(ent.text, ent.label_)\n",
    "    print()\n",
    "\n",
    "\n",
    "textos = (\n",
    "    \"L'empresa Apple està buscant comprar una empresa a Anglaterra per mil milions d'euros\",\n",
    "    \"Com em puc fer soci del Barça?\",\n",
    "    \"Som a l'Eixample Clínic, prop de Pl Catalunya.\",\n",
    ")\n",
    "\n",
    "for text in textos:\n",
    "    mostra_ner(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consell: el mètode spacy.explain\n",
    "\n",
    "Una pregunta ràpida: què significa \"ORG\"? Què passa amb \"NNP\" o \"dobj\"?\n",
    "\n",
    "En els casos en què necessites saber el significat d'una etiqueta de categoria gramatical o una etiqueta de dependència, pots utilitzar la funció auxiliar spacy.explain.\n",
    "\n",
    "El mateix funciona per a etiquetes de categoria gramatical i etiquetes de dependència."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"PER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"NNP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"MISC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció d'anotacions lingüístiques\n",
    "\n",
    "Ara podràs provar un dels paquets de models pre-entrenats de spaCy i veure les seves prediccions en acció. Prova-ho amb el teu propi text! Per esbrinar què significa una etiqueta, pots cridar spacy.explain. Per exemple: spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Processa el text amb l'objecte nlp i crea un doc.\n",
    "\n",
    "Per a cada token, imprimeix el text del token, l'atribut pos_ del token i l'atribut dep_ del token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It's official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"nsubj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "text = \"És oficial: Apple és la primera empresa americana a assolir el valor de mercat d'un bilió d'euros\"\n",
    "\n",
    "# Processa el text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Obté el text del token, l'etiqueta de categoria gramatical i l'etiqueta de dependència\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # Això és només per formatar\n",
    "    print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"cop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"ROOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"acl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"nummod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"nmod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ca_core_news_sm\")\n",
    "\n",
    "text = \"La meva entrada encara no ha arribat. Com faig per entrar al partit\"\n",
    "\n",
    "# Processa el text\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    # Obté el text del token, l'etiqueta de categoria gramatical i l'etiqueta de dependència\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # Això és només per formatar\n",
    "    print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.explain(\"acl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Processa el text i crea un objecte doc.\n",
    "\n",
    "Itera sobre doc.ents i imprimeix el text de l'entitat i l'atribut label_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"It's official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"I want to buy a tennis shoes and pay 120 dollars\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció d'entitats amb nom en context\n",
    "\n",
    "Els models són estadístics i no sempre tenen raó. Si les seves prediccions són correctes depèn de les dades d'entrenament i del text que estàs processant. Vegem un exemple.\n",
    "\n",
    "Processa el text amb l'objecte nlp.\n",
    "\n",
    "Itera sobre les entitats i imprimeix el text de l'entitat i l'etiqueta.\n",
    "\n",
    "Sembla que el model no ha predit \"iPhone X\". Crea un span per a aquests tokens manualment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "text = \"New iPhone X release date leaked as Apple reveals pre-orders by mistake\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the entities\n",
    "for token in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(token.text, token.label_)\n",
    "\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordança basada en regles\n",
    "\n",
    "Ara veurem el matcher de spaCy, que et permet escriure regles per trobar paraules i frases en text.\n",
    "\n",
    "Comparat amb expressions regulars, el matcher treballa amb objectes Doc i Token en lloc de només cadenes de text.\n",
    "\n",
    "També és més flexible: pots cercar textos però també altres atributs lèxics.\n",
    "\n",
    "Fins i tot pots escriure regles que utilitzin les prediccions del model.\n",
    "\n",
    "Per exemple, trobar la paraula \"duck\" només si és un verb, no un nom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per què no només expressions regulars?\n",
    "\n",
    "<ul>\n",
    "<li>Concordança amb objectes Doc, no només cadenes de text</li>\n",
    "\n",
    "<li>Concordança amb tokens i atributs de token</li>\n",
    "\n",
    "<li>Utilitza les prediccions del model</li>\n",
    "\n",
    "<li>Exemple: \"duck\" (verb) vs. \"duck\" (nom)</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els patrons de concordança són llistes de diccionaris. Cada diccionari descriu un token. Les claus són els noms dels atributs de token, mapeats als seus valors esperats.\n",
    "\n",
    "En aquest exemple, estem buscant dos tokens amb el text \"iPhone\" i \"X\".\n",
    "\n",
    "També podem fer concordances amb altres atributs de token. Aquí, estem buscant dos tokens les etiquetes de categoria gramatical dels quals són \"VERB\" i \"NOUN\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ús del Matcher (1)\n",
    "\n",
    "Per utilitzar un patró, primer importem el matcher de spacy.matcher.\n",
    "\n",
    "També carregem un model i obtenim l'objecte nlp.\n",
    "\n",
    "El matcher s'inicialitza amb el vocabulari compartit, nlp.vocab. El necessitaràs més endavant.\n",
    "\n",
    "El mètode matcher.add et permet afegir un patró. El primer argument és un ID únic per identificar quin patró s'ha trobat. El segon argument és una llista de patrons.\n",
    "\n",
    "Per fer concordar el patró amb un text, podem cridar el matcher amb qualsevol doc.\n",
    "\n",
    "Això retornarà les concordances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a model and create the nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "matcher.add(\"IPHONE_PATTERN\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "doc = nlp(\"New iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ús del Matcher (2)\n",
    "\n",
    "Quan cridades el matcher amb un doc, retorna una llista de tuples.\n",
    "\n",
    "Cada tupla consta de tres valors: l'ID de la concordança, l'índex d'inici i l'índex final del span concordat.\n",
    "\n",
    "Això significa que podem iterar sobre les concordances i crear un objecte Span: un fragment del doc a l'índex d'inici i final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the matcher on the doc\n",
    "doc = nlp(\"New iPhone X release date leaked\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordança d'atributs de lèxic\n",
    "\n",
    "Aquí tens un exemple d'un patró més complex utilitzant atributs de lèxic.\n",
    "\n",
    "Estem buscant cinc tokens:\n",
    "\n",
    "Un token format només de dígits.\n",
    "\n",
    "Tres tokens sensibles a majúscules per a \"fifa\", \"world\" i \"cup\".\n",
    "\n",
    "I un token que consisteix en puntuació.\n",
    "\n",
    "El patró coincideix amb els tokens \"2018 FIFA World Cup:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {\"IS_DIGIT\": True},\n",
    "    {\"LOWER\": \"fifa\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"},\n",
    "    {\"IS_PUNCT\": True},\n",
    "]\n",
    "\n",
    "doc = nlp(\"2018 FIFA World Cup: France won!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordança amb altres atributs de token\n",
    "\n",
    "En aquest exemple, estem buscant dos tokens:\n",
    "\n",
    "Un verb amb la forma lematitzada \"love\", seguit d'un nom.\n",
    "\n",
    "Aquest patró concordarà amb \"loved dogs\" i \"love cats\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LEMMA\": \"love\", \"POS\": \"VERB\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "doc = nlp(\"I loved dogs but now I love cats more.\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"PETS\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LEMMA\": \"love\", \"POS\": \"VERB\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "doc = nlp(\"I loved dogs. Now I love cats more.\")\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"PETS\", [pattern])\n",
    "\n",
    "# Process some text\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ús d'operadors i quantificadors (1)\n",
    "\n",
    "Els operadors i quantificadors et permeten definir quantes vegades ha de concordar un token. Es poden afegir utilitzant la clau \"OP\".\n",
    "\n",
    "Aquí, l'operador \"?\" fa que el token determinant sigui opcional, així que concordarà amb un token amb el lema \"buy\", un substantiu opcional i un últim substantiu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{\"LEMMA\": \"buy\"}, {\"POS\": \"DET\", \"OP\": \"?\"}, {\"POS\": \"NOUN\"}]\n",
    "\n",
    "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ús d'operadors i quantificadors (2)\n",
    "\n",
    "\"OP\" pot tenir un de quatre valors:\n",
    "\n",
    "Un \"!\" nega el token, així que ha de concordar 0 vegades.\n",
    "\n",
    "Un \"?\" fa que el token sigui opcional, i ha de concordar 0 o 1 vegada.\n",
    "\n",
    "Un \"+\" fa que el token concordi 1 o més vegades.\n",
    "\n",
    "I un \"*\" fa que el token concordi 0 o més vegades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ús del Matcher\n",
    "\n",
    "Provem d'utilitzar els mètodes basats en regles de spaCy del nou matcher. Utilitzaràs l'exemple de l'exercici anterior i escriuràs un patró que pugui fer concordar la frase \"iPhone X\" al text.\n",
    "\n",
    "Importa el Matcher de spacy.matcher.\n",
    "\n",
    "Inicialitza'l amb el vocab de l'objecte nlp.\n",
    "\n",
    "Crea un patró que concordi amb els valors \"TEXT\" per a dos tokens: \"iPhone\" i \"X\".\n",
    "\n",
    "Utilitza el mètode matcher.add per afegir el patró al matcher.\n",
    "\n",
    "Crida el matcher amb el doc i emmagatzema el resultat a la variable matches.\n",
    "\n",
    "Itera sobre les concordances i obté el span concordat des de l'índex d'inici fins a l'índex final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"New iPhone X release date leaked as Apple reveals pre-orders by mistake\")\n",
    "\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrivint patrons de concordança\n",
    "\n",
    "En aquest exercici, practicaràs escrivint patrons de concordança més complexos utilitzant diferents atributs de token i operadors.\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Escriu un patró que només concordi amb mencions de les versions completes d'iOS: \"iOS 7\", \"iOS 11\" i \"iOS 10\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"After making the iOS update you won't notice a radical system-wide \"\n",
    "    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
    "    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
    "    \"some tweaks once you delve a little deeper.\"\n",
    ")\n",
    "\n",
    "# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"IOS_VERSION_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Escriu un patró que només concordi amb formes de \"download\" (tokens amb el lema \"download\"), seguides d'un nom propi (token amb etiqueta de categoria gramatical \"PROPN\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
    "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
    "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
    "    \"I also need to download Winzip?\"\n",
    ")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Escriu un patró que concordi amb adjectius (\"ADJ\") seguits d'un o dos noms (un nom i un nom opcional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\n",
    "    \"Features of the app include a beautiful design, smart search, automatic \" \"labels and optional voice responses.\"\n",
    ")\n",
    "\n",
    "# Write a pattern for adjective plus one or two nouns\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\", [pattern])\n",
    "matches = matcher(doc)\n",
    "print(\"Total matches found:\", len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print(\"Match found:\", doc[start:end].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Taula de continguts",
   "title_sidebar": "Continguts",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "332.807px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
